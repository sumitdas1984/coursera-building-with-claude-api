{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-haiku-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83809a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa99d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30fae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 5.666666666666667\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"# AWS CloudFormation Template Parser\\n\\nI'll create a solution to parse AWS CloudFormation templates and extract all resource logical IDs.\\n\\n```python\\nimport json\\nimport yaml\\nfrom typing import List, Set\\n\\ndef extract_resource_ids_from_cloudformation(template_content: str, is_json: bool = None) -> List[str]:\\n    \\\"\\\"\\\"\\n    Parse an AWS CloudFormation template and extract all resource logical IDs.\\n    \\n    Args:\\n        template_content: The CloudFormation template as a string (JSON or YAML)\\n        is_json: Optional boolean to specify format. If None, will try to auto-detect.\\n    \\n    Returns:\\n        List of resource logical IDs\\n    \\\"\\\"\\\"\\n    template = None\\n    \\n    # Auto-detect format if not specified\\n    if is_json is None:\\n        try:\\n            template = json.loads(template_content)\\n            is_json = True\\n        except json.JSONDecodeError:\\n            try:\\n                template = yaml.safe_load(template_content)\\n                is_json = False\\n            except yaml.YAMLError:\\n                raise ValueError(\\\"Template is neither valid JSON nor valid YAML\\\")\\n    else:\\n        # Parse based on specified format\\n        if is_json:\\n            template = json.loads(template_content)\\n        else:\\n            template = yaml.safe_load(template_content)\\n    \\n    # Extract Resources section\\n    if not isinstance(template, dict):\\n        raise ValueError(\\\"CloudFormation template must be a JSON object or YAML mapping\\\")\\n    \\n    resources = template.get(\\\"Resources\\\", {})\\n    \\n    if not isinstance(resources, dict):\\n        raise ValueError(\\\"Resources section must be a mapping/object\\\")\\n    \\n    # Get all logical IDs (keys in the Resources section)\\n    logical_ids = list(resources.keys())\\n    \\n    return sorted(logical_ids)\\n\\n\\ndef extract_and_display_resources(template_content: str) -> None:\\n    \\\"\\\"\\\"\\n    Parse template and display resource information.\\n    \\\"\\\"\\\"\\n    logical_ids = extract_resource_ids_from_cloudformation(template_content)\\n    \\n    print(\\\"CloudFormation Resource Logical IDs:\\\")\\n    print(\\\"=\\\" * 50)\\n    print(f\\\"Total Resources: {len(logical_ids)}\\\\n\\\")\\n    \\n    for idx, resource_id in enumerate(logical_ids, 1):\\n        print(f\\\"{idx}. {resource_id}\\\")\\n\\n\\n# Example Usage\\nif __name__ == \\\"__main__\\\":\\n    # Example 1: JSON Template\\n    json_template = \\\"\\\"\\\"\\n    {\\n        \\\"AWSTemplateFormatVersion\\\": \\\"2010-09-09\\\",\\n        \\\"Description\\\": \\\"Sample CloudFormation Template\\\",\\n        \\\"Resources\\\": {\\n            \\\"MyS3Bucket\\\": {\\n                \\\"Type\\\": \\\"AWS::S3::Bucket\\\",\\n                \\\"Properties\\\": {\\n                    \\\"BucketName\\\": \\\"my-sample-bucket\\\"\\n                }\\n            },\\n            \\\"MyEC2Instance\\\": {\\n                \\\"Type\\\": \\\"AWS::EC2::Instance\\\",\\n                \\\"Properties\\\": {\\n                    \\\"ImageId\\\": \\\"ami-0c55b159cbfafe1f0\\\",\\n                    \\\"InstanceType\\\": \\\"t2.micro\\\"\\n                }\\n            },\\n            \\\"MySecurityGroup\\\": {\\n                \\\"Type\\\": \\\"AWS::EC2::SecurityGroup\\\",\\n                \\\"Properties\\\": {\\n                    \\\"GroupDescription\\\": \\\"Security group for web server\\\"\\n                }\\n            }\\n        }\\n    }\\n    \\\"\\\"\\\"\\n    \\n    # Example 2: YAML Template\\n    yaml_template = \\\"\\\"\\\"\\nAWSTemplateFormatVersion: '2010-09-09'\\nDescription: Sample CloudFormation Template in YAML\\nResources:\\n  MyVPC:\\n    Type: AWS::EC2::VPC\\n    Properties:\\n      CidrBlock: 10.0.0.0/16\\n  \\n  MySubnet:\\n    Type: AWS::EC2::Subnet\\n    Properties:\\n      VpcId: !Ref MyVPC\\n      CidrBlock: 10.0.1.0/24\\n  \\n  MyRDSDatabase:\\n    Type: AWS::RDS::DBInstance\\n    Properties:\\n      DBInstanceClass: db.t2.micro\\n      Engine: mysql\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Parse an AWS CloudFormation template and extract all resource logical IDs\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution demonstrates solid fundamentals for parsing CloudFormation templates with good error handling and format flexibility. The code is well-structured and readable. However, it's incomplete as presented (examples aren't fully shown executing), and it lacks robustness for real-world scenarios like validation of resource structure or handling of complex CloudFormation features. The core requirement is met, but production use would need additional validation and edge case handling.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# AWS IAM Policy JSON Validator and Formatter\\n\\nI'll provide you with a comprehensive solution to validate and format AWS IAM policy JSON documents.\\n\\n```python\\nimport json\\nimport re\\nfrom typing import Dict, List, Tuple, Any\\nfrom jsonschema import validate, ValidationError, Draft7Validator\\n\\nclass IAMPolicyValidator:\\n    \\\"\\\"\\\"Validates and formats AWS IAM policy documents.\\\"\\\"\\\"\\n    \\n    # IAM Policy Schema (simplified)\\n    POLICY_SCHEMA = {\\n        \\\"type\\\": \\\"object\\\",\\n        \\\"properties\\\": {\\n            \\\"Version\\\": {\\\"type\\\": \\\"string\\\"},\\n            \\\"Statement\\\": {\\n                \\\"type\\\": \\\"array\\\",\\n                \\\"items\\\": {\\n                    \\\"type\\\": \\\"object\\\",\\n                    \\\"properties\\\": {\\n                        \\\"Sid\\\": {\\\"type\\\": \\\"string\\\"},\\n                        \\\"Effect\\\": {\\\"enum\\\": [\\\"Allow\\\", \\\"Deny\\\"]},\\n                        \\\"Principal\\\": {},\\n                        \\\"NotPrincipal\\\": {},\\n                        \\\"Action\\\": {},\\n                        \\\"NotAction\\\": {},\\n                        \\\"Resource\\\": {},\\n                        \\\"NotResource\\\": {},\\n                        \\\"Condition\\\": {\\\"type\\\": \\\"object\\\"}\\n                    },\\n                    \\\"required\\\": [\\\"Effect\\\"]\\n                }\\n            }\\n        },\\n        \\\"required\\\": [\\\"Version\\\", \\\"Statement\\\"]\\n    }\\n    \\n    VALID_ACTIONS = {\\n        \\\"s3\\\": [\\\"s3:GetObject\\\", \\\"s3:PutObject\\\", \\\"s3:DeleteObject\\\", \\\"s3:ListBucket\\\"],\\n        \\\"ec2\\\": [\\\"ec2:DescribeInstances\\\", \\\"ec2:StartInstances\\\", \\\"ec2:StopInstances\\\"],\\n        \\\"iam\\\": [\\\"iam:GetUser\\\", \\\"iam:ListUsers\\\", \\\"iam:CreateUser\\\"],\\n        \\\"dynamodb\\\": [\\\"dynamodb:GetItem\\\", \\\"dynamodb:PutItem\\\", \\\"dynamodb:Query\\\"],\\n    }\\n    \\n    def __init__(self):\\n        self.errors: List[str] = []\\n        self.warnings: List[str] = []\\n    \\n    def validate_policy(self, policy_json: str) -> Tuple[bool, Dict[str, Any]]:\\n        \\\"\\\"\\\"\\n        Validate IAM policy JSON document.\\n        \\n        Args:\\n            policy_json: JSON string of IAM policy\\n            \\n        Returns:\\n            Tuple of (is_valid, result_dict)\\n        \\\"\\\"\\\"\\n        self.errors = []\\n        self.warnings = []\\n        \\n        try:\\n            # Parse JSON\\n            policy = json.loads(policy_json)\\n        except json.JSONDecodeError as e:\\n            self.errors.append(f\\\"Invalid JSON syntax: {str(e)}\\\")\\n            return False, self._get_result_dict(policy_json)\\n        \\n        # Validate against schema\\n        try:\\n            validate(instance=policy, schema=self.POLICY_SCHEMA)\\n        except ValidationError as e:\\n            self.errors.append(f\\\"Schema validation error: {str(e)}\\\")\\n        \\n        # Additional validations\\n        self._validate_policy_structure(policy)\\n        self._validate_statements(policy.get(\\\"Statement\\\", []))\\n        \\n        is_valid = len(self.errors) == 0\\n        return is_valid, self._get_result_dict(policy_json)\\n    \\n    def _validate_policy_structure(self, policy: Dict) -> None:\\n        \\\"\\\"\\\"Validate overall policy structure.\\\"\\\"\\\"\\n        if \\\"Version\\\" not in policy:\\n            self.errors.append(\\\"Missing required field: 'Version'\\\")\\n        elif policy[\\\"Version\\\"] not in [\\\"2012-10-17\\\", \\\"2008-10-17\\\"]:\\n            self.warnings.append(\\n                f\\\"Unusual Version: {policy['Version']}. \\\"\\n                \\\"Standard version is '2012-10-17'\\\"\\n            )\\n        \\n        if \\\"Statement\\\" not in policy:\\n            self.errors.append(\\\"Missing required field: 'Statement'\\\")\\n        elif not isinstance(policy[\\\"Statement\\\"], list):\\n            self.errors.append(\\\"'Statement' must be an array\\\")\\n        elif len(policy[\\\"Statement\\\"]) == 0:\\n            self.warnings.append(\\\"'Statement' array is empty\\\")\\n    \\n    def _validate_statements(self, statements: List[Dict]) -> None:\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Validate and format an AWS IAM policy JSON document\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 4,\n",
      "    \"reasoning\": \"While the code demonstrates understanding of validation architecture and good coding practices, it's incomplete and incomplete for production use. The missing formatting functionality (stated in task title), incomplete statement validation, and oversimplified schema make this unsuitable for validating real AWS IAM policies. The hardcoded action list is a significant limitation that doesn't reflect AWS's actual scope of services and actions.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# Extract AWS S3 Bucket Names from CloudTrail Logs\\n\\nHere's a comprehensive solution with multiple approaches:\\n\\n## Solution 1: Using Regular Expressions (Simple)\\n\\n```python\\nimport re\\nimport json\\n\\ndef extract_s3_buckets_regex(cloudtrail_logs):\\n    \\\"\\\"\\\"Extract S3 bucket names using regex patterns\\\"\\\"\\\"\\n    s3_buckets = set()\\n    \\n    # Patterns for common S3 ARNs and references\\n    patterns = [\\n        r'arn:aws:s3:::([a-z0-9.-]+)',  # S3 ARN pattern\\n        r'\\\"bucketName\\\":\\\\s*\\\"([a-z0-9.-]+)\\\"',  # JSON field\\n        r'bucket[\\\"\\\\']?\\\\s*:\\\\s*[\\\"\\\\']([a-z0-9.-]+)[\\\"\\\\']',  # bucket field\\n    ]\\n    \\n    log_text = json.dumps(cloudtrail_logs) if isinstance(cloudtrail_logs, dict) else str(cloudtrail_logs)\\n    \\n    for pattern in patterns:\\n        matches = re.finditer(pattern, log_text, re.IGNORECASE)\\n        s3_buckets.update(match.group(1) for match in matches)\\n    \\n    return s3_buckets\\n\\n# Example usage\\nsample_logs = {\\n    \\\"Records\\\": [\\n        {\\n            \\\"eventSource\\\": \\\"s3.amazonaws.com\\\",\\n            \\\"requestParameters\\\": {\\n                \\\"bucketName\\\": \\\"my-data-bucket\\\"\\n            },\\n            \\\"resources\\\": [\\n                {\\n                    \\\"ARN\\\": \\\"arn:aws:s3:::my-data-bucket\\\",\\n                    \\\"accountId\\\": \\\"123456789012\\\",\\n                    \\\"type\\\": \\\"AWS::S3::Bucket\\\"\\n                }\\n            ]\\n        }\\n    ]\\n}\\n\\nbuckets = extract_s3_buckets_regex(sample_logs)\\nprint(\\\"Found S3 Buckets:\\\", buckets)\\n```\\n\\n## Solution 2: Parsing CloudTrail JSON Structure (Recommended)\\n\\n```python\\nimport json\\nfrom typing import Set, Any\\n\\ndef extract_s3_buckets_structured(cloudtrail_logs: dict) -> Set[str]:\\n    \\\"\\\"\\\"Extract S3 bucket names by parsing CloudTrail JSON structure\\\"\\\"\\\"\\n    s3_buckets = set()\\n    \\n    if isinstance(cloudtrail_logs, str):\\n        cloudtrail_logs = json.loads(cloudtrail_logs)\\n    \\n    records = cloudtrail_logs.get('Records', [])\\n    \\n    for record in records:\\n        # Check event source\\n        if record.get('eventSource') != 's3.amazonaws.com':\\n            continue\\n        \\n        # Extract from resources\\n        for resource in record.get('resources', []):\\n            if resource.get('type') == 'AWS::S3::Bucket':\\n                arn = resource.get('ARN', '')\\n                bucket_name = arn.split('::')[-1]\\n                if bucket_name:\\n                    s3_buckets.add(bucket_name)\\n        \\n        # Extract from request parameters\\n        request_params = record.get('requestParameters', {})\\n        if isinstance(request_params, dict):\\n            if 'bucketName' in request_params:\\n                s3_buckets.add(request_params['bucketName'])\\n            if 'Bucket' in request_params:\\n                s3_buckets.add(request_params['Bucket'])\\n        \\n        # Extract from response elements\\n        response_elements = record.get('responseElements', {})\\n        if isinstance(response_elements, dict):\\n            if 'bucket' in response_elements:\\n                s3_buckets.add(response_elements['bucket'])\\n    \\n    return s3_buckets\\n\\n# Example usage\\nsample_cloudtrail = {\\n    \\\"Records\\\": [\\n        {\\n            \\\"eventVersion\\\": \\\"1.07\\\",\\n            \\\"userIdentity\\\": {\\\"type\\\": \\\"IAMUser\\\"},\\n            \\\"eventTime\\\": \\\"2024-01-15T10:30:00Z\\\",\\n            \\\"eventSource\\\": \\\"s3.amazonaws.com\\\",\\n            \\\"eventName\\\": \\\"PutObject\\\",\\n            \\\"requestParameters\\\": {\\\"\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Extract AWS S3 bucket names from CloudTrail logs using pattern matching\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 6,\n",
      "    \"reasoning\": \"The solution correctly identifies that structured parsing is superior to regex for CloudTrail logs and implements the recommended approach with proper schema navigation. However, Solution 1 undermines credibility with flawed regex patterns, and the incomplete Solution 2 example leaves implementation gaps. The solution lacks validation of extracted bucket names and doesn't address edge cases like nested or encoded bucket references common in real CloudTrail logs. While the foundation is sound, execution is incomplete and inconsistent.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e40a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
